{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\steve\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=1.20s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 591753/591753 [00:58<00:00, 10106.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 64          # batch size\n",
    "vocab_threshold = 3        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 2048           # dimensionality of image and word embeddings\n",
    "hidden_size = 2048          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 2             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/9247], Loss: 4.9134, Perplexity: 136.0949\n",
      "Epoch [1/2], Step [200/9247], Loss: 4.9119, Perplexity: 135.8963\n",
      "Epoch [1/2], Step [300/9247], Loss: 5.1109, Perplexity: 165.8149\n",
      "Epoch [1/2], Step [400/9247], Loss: 4.8898, Perplexity: 132.9264\n",
      "Epoch [1/2], Step [500/9247], Loss: 4.8505, Perplexity: 127.7997\n",
      "Epoch [1/2], Step [600/9247], Loss: 4.9295, Perplexity: 138.3126\n",
      "Epoch [1/2], Step [700/9247], Loss: 4.7062, Perplexity: 110.6267\n",
      "Epoch [1/2], Step [800/9247], Loss: 4.9173, Perplexity: 136.6268\n",
      "Epoch [1/2], Step [900/9247], Loss: 4.6616, Perplexity: 105.8053\n",
      "Epoch [1/2], Step [1000/9247], Loss: 5.3972, Perplexity: 220.7977\n",
      "Epoch [1/2], Step [1100/9247], Loss: 5.0442, Perplexity: 155.1211\n",
      "Epoch [1/2], Step [1200/9247], Loss: 4.8480, Perplexity: 127.4914\n",
      "Epoch [1/2], Step [1300/9247], Loss: 5.1895, Perplexity: 179.3877\n",
      "Epoch [1/2], Step [1400/9247], Loss: 4.8009, Perplexity: 121.6219\n",
      "Epoch [1/2], Step [1500/9247], Loss: 5.1392, Perplexity: 170.5714\n",
      "Epoch [1/2], Step [1600/9247], Loss: 4.7261, Perplexity: 112.8532\n",
      "Epoch [1/2], Step [1700/9247], Loss: 4.9915, Perplexity: 147.1606\n",
      "Epoch [1/2], Step [1800/9247], Loss: 4.7381, Perplexity: 114.2128\n",
      "Epoch [1/2], Step [1900/9247], Loss: 4.9724, Perplexity: 144.3793\n",
      "Epoch [1/2], Step [2000/9247], Loss: 4.8545, Perplexity: 128.3106\n",
      "Epoch [1/2], Step [2100/9247], Loss: 4.6594, Perplexity: 105.5742\n",
      "Epoch [1/2], Step [2200/9247], Loss: 4.5857, Perplexity: 98.0698\n",
      "Epoch [1/2], Step [2300/9247], Loss: 5.4423, Perplexity: 230.9743\n",
      "Epoch [1/2], Step [2400/9247], Loss: 4.6922, Perplexity: 109.0892\n",
      "Epoch [1/2], Step [2500/9247], Loss: 5.1127, Perplexity: 166.1114\n",
      "Epoch [1/2], Step [2600/9247], Loss: 4.9479, Perplexity: 140.8750\n",
      "Epoch [1/2], Step [2700/9247], Loss: 4.8820, Perplexity: 131.8989\n",
      "Epoch [1/2], Step [2800/9247], Loss: 4.7324, Perplexity: 113.5627\n",
      "Epoch [1/2], Step [2900/9247], Loss: 4.7621, Perplexity: 116.9885\n",
      "Epoch [1/2], Step [3000/9247], Loss: 4.5501, Perplexity: 94.6387\n",
      "Epoch [1/2], Step [3100/9247], Loss: 4.6690, Perplexity: 106.5869\n",
      "Epoch [1/2], Step [3200/9247], Loss: 5.1885, Perplexity: 179.1954\n",
      "Epoch [1/2], Step [3300/9247], Loss: 4.8729, Perplexity: 130.7000\n",
      "Epoch [1/2], Step [3400/9247], Loss: 5.2350, Perplexity: 187.7352\n",
      "Epoch [1/2], Step [3500/9247], Loss: 5.0332, Perplexity: 153.4281\n",
      "Epoch [1/2], Step [3600/9247], Loss: 5.1304, Perplexity: 169.0903\n",
      "Epoch [1/2], Step [3700/9247], Loss: 4.7380, Perplexity: 114.2046\n",
      "Epoch [1/2], Step [3800/9247], Loss: 4.9165, Perplexity: 136.5193\n",
      "Epoch [1/2], Step [3900/9247], Loss: 4.9800, Perplexity: 145.4796\n",
      "Epoch [1/2], Step [4000/9247], Loss: 4.7136, Perplexity: 111.4543\n",
      "Epoch [1/2], Step [4100/9247], Loss: 4.7599, Perplexity: 116.7293\n",
      "Epoch [1/2], Step [4200/9247], Loss: 4.8982, Perplexity: 134.0548\n",
      "Epoch [1/2], Step [4300/9247], Loss: 4.7250, Perplexity: 112.7273\n",
      "Epoch [1/2], Step [4400/9247], Loss: 4.7890, Perplexity: 120.1816\n",
      "Epoch [1/2], Step [4500/9247], Loss: 4.9302, Perplexity: 138.4087\n",
      "Epoch [1/2], Step [4600/9247], Loss: 4.6733, Perplexity: 107.0497\n",
      "Epoch [1/2], Step [4700/9247], Loss: 4.9093, Perplexity: 135.5381\n",
      "Epoch [1/2], Step [4800/9247], Loss: 4.8584, Perplexity: 128.8160\n",
      "Epoch [1/2], Step [4900/9247], Loss: 4.9053, Perplexity: 135.0101\n",
      "Epoch [1/2], Step [5000/9247], Loss: 4.7739, Perplexity: 118.3843\n",
      "Epoch [1/2], Step [5100/9247], Loss: 4.8116, Perplexity: 122.9316\n",
      "Epoch [1/2], Step [5200/9247], Loss: 4.7297, Perplexity: 113.2600\n",
      "Epoch [1/2], Step [5300/9247], Loss: 4.6460, Perplexity: 104.1708\n",
      "Epoch [1/2], Step [5400/9247], Loss: 4.7628, Perplexity: 117.0686\n",
      "Epoch [1/2], Step [5500/9247], Loss: 4.6060, Perplexity: 100.0859\n",
      "Epoch [1/2], Step [5600/9247], Loss: 4.8956, Perplexity: 133.7058\n",
      "Epoch [1/2], Step [5700/9247], Loss: 4.7999, Perplexity: 121.4998\n",
      "Epoch [1/2], Step [5800/9247], Loss: 4.6023, Perplexity: 99.7168\n",
      "Epoch [1/2], Step [5900/9247], Loss: 4.7397, Perplexity: 114.3993\n",
      "Epoch [1/2], Step [6000/9247], Loss: 4.7194, Perplexity: 112.0997\n",
      "Epoch [1/2], Step [6100/9247], Loss: 4.7189, Perplexity: 112.0501\n",
      "Epoch [1/2], Step [6200/9247], Loss: 4.6266, Perplexity: 102.1701\n",
      "Epoch [1/2], Step [6300/9247], Loss: 4.5435, Perplexity: 94.0207\n",
      "Epoch [1/2], Step [6400/9247], Loss: 5.2315, Perplexity: 187.0804\n",
      "Epoch [1/2], Step [6500/9247], Loss: 5.0697, Perplexity: 159.1232\n",
      "Epoch [1/2], Step [6600/9247], Loss: 5.3775, Perplexity: 216.4769\n",
      "Epoch [1/2], Step [6700/9247], Loss: 5.0843, Perplexity: 161.4710\n",
      "Epoch [1/2], Step [6800/9247], Loss: 4.8290, Perplexity: 125.0807\n",
      "Epoch [1/2], Step [6900/9247], Loss: 4.8719, Perplexity: 130.5654\n",
      "Epoch [1/2], Step [7000/9247], Loss: 4.6855, Perplexity: 108.3649\n",
      "Epoch [1/2], Step [7100/9247], Loss: 4.6787, Perplexity: 107.6284\n",
      "Epoch [1/2], Step [7200/9247], Loss: 4.6557, Perplexity: 105.1823\n",
      "Epoch [1/2], Step [7300/9247], Loss: 4.9632, Perplexity: 143.0536\n",
      "Epoch [1/2], Step [7400/9247], Loss: 4.6546, Perplexity: 105.0649\n",
      "Epoch [1/2], Step [7500/9247], Loss: 4.5818, Perplexity: 97.6945\n",
      "Epoch [1/2], Step [7600/9247], Loss: 4.4079, Perplexity: 82.0956\n",
      "Epoch [1/2], Step [7700/9247], Loss: 5.0864, Perplexity: 161.8057\n",
      "Epoch [1/2], Step [7800/9247], Loss: 4.6717, Perplexity: 106.8779\n",
      "Epoch [1/2], Step [7900/9247], Loss: 4.6268, Perplexity: 102.1855\n",
      "Epoch [1/2], Step [8000/9247], Loss: 4.6328, Perplexity: 102.8038\n",
      "Epoch [1/2], Step [8100/9247], Loss: 5.0065, Perplexity: 149.3842\n",
      "Epoch [1/2], Step [8200/9247], Loss: 4.7700, Perplexity: 117.9176\n",
      "Epoch [1/2], Step [8300/9247], Loss: 4.7395, Perplexity: 114.3809\n",
      "Epoch [1/2], Step [8400/9247], Loss: 4.8990, Perplexity: 134.1521\n",
      "Epoch [1/2], Step [8500/9247], Loss: 4.8743, Perplexity: 130.8889\n",
      "Epoch [1/2], Step [8600/9247], Loss: 4.6674, Perplexity: 106.4229\n",
      "Epoch [1/2], Step [8700/9247], Loss: 5.0388, Perplexity: 154.2817\n",
      "Epoch [1/2], Step [8800/9247], Loss: 5.1816, Perplexity: 177.9660\n",
      "Epoch [1/2], Step [8900/9247], Loss: 4.7292, Perplexity: 113.2019\n",
      "Epoch [1/2], Step [9000/9247], Loss: 4.7562, Perplexity: 116.3017\n",
      "Epoch [1/2], Step [9100/9247], Loss: 5.3700, Perplexity: 214.8726\n",
      "Epoch [1/2], Step [9200/9247], Loss: 5.4291, Perplexity: 227.9448\n",
      "Epoch [1/2], Step [9247/9247], Loss: 4.6709, Perplexity: 106.7940\n",
      "Saving the model\n",
      "Epoch [2/2], Step [100/9247], Loss: 4.7053, Perplexity: 110.5363\n",
      "Epoch [2/2], Step [200/9247], Loss: 4.5652, Perplexity: 96.0813\n",
      "Epoch [2/2], Step [300/9247], Loss: 4.6412, Perplexity: 103.6738\n",
      "Epoch [2/2], Step [400/9247], Loss: 4.5512, Perplexity: 94.7466\n",
      "Epoch [2/2], Step [500/9247], Loss: 4.7881, Perplexity: 120.0748\n",
      "Epoch [2/2], Step [600/9247], Loss: 4.7654, Perplexity: 117.3789\n",
      "Epoch [2/2], Step [700/9247], Loss: 5.6365, Perplexity: 280.4695\n",
      "Epoch [2/2], Step [800/9247], Loss: 4.6661, Perplexity: 106.2807\n",
      "Epoch [2/2], Step [900/9247], Loss: 4.7479, Perplexity: 115.3473\n",
      "Epoch [2/2], Step [1000/9247], Loss: 4.9581, Perplexity: 142.3257\n",
      "Epoch [2/2], Step [1100/9247], Loss: 4.6207, Perplexity: 101.5605\n",
      "Epoch [2/2], Step [1200/9247], Loss: 4.5963, Perplexity: 99.1203\n",
      "Epoch [2/2], Step [1300/9247], Loss: 4.5088, Perplexity: 90.8170\n",
      "Epoch [2/2], Step [1400/9247], Loss: 4.8796, Perplexity: 131.5802\n",
      "Epoch [2/2], Step [1500/9247], Loss: 4.6003, Perplexity: 99.5160\n",
      "Epoch [2/2], Step [1600/9247], Loss: 4.6056, Perplexity: 100.0467\n",
      "Epoch [2/2], Step [1700/9247], Loss: 4.7605, Perplexity: 116.8047\n",
      "Epoch [2/2], Step [1800/9247], Loss: 4.5882, Perplexity: 98.3129\n",
      "Epoch [2/2], Step [1900/9247], Loss: 4.8374, Perplexity: 126.1421\n",
      "Epoch [2/2], Step [2000/9247], Loss: 4.7364, Perplexity: 114.0264\n",
      "Epoch [2/2], Step [2100/9247], Loss: 4.5401, Perplexity: 93.7047\n",
      "Epoch [2/2], Step [2200/9247], Loss: 4.6008, Perplexity: 99.5596\n",
      "Epoch [2/2], Step [2300/9247], Loss: 4.8150, Perplexity: 123.3505\n",
      "Epoch [2/2], Step [2400/9247], Loss: 4.6746, Perplexity: 107.1847\n",
      "Epoch [2/2], Step [2500/9247], Loss: 4.5549, Perplexity: 95.0984\n",
      "Epoch [2/2], Step [2600/9247], Loss: 5.1251, Perplexity: 168.1867\n",
      "Epoch [2/2], Step [2700/9247], Loss: 4.7483, Perplexity: 115.3898\n",
      "Epoch [2/2], Step [2800/9247], Loss: 4.8407, Perplexity: 126.5636\n",
      "Epoch [2/2], Step [2900/9247], Loss: 4.5721, Perplexity: 96.7516\n",
      "Epoch [2/2], Step [3000/9247], Loss: 4.5264, Perplexity: 92.4269\n",
      "Epoch [2/2], Step [3100/9247], Loss: 4.5406, Perplexity: 93.7424\n",
      "Epoch [2/2], Step [3200/9247], Loss: 4.9162, Perplexity: 136.4829\n",
      "Epoch [2/2], Step [3300/9247], Loss: 4.8680, Perplexity: 130.0649\n",
      "Epoch [2/2], Step [3400/9247], Loss: 4.7743, Perplexity: 118.4219\n",
      "Epoch [2/2], Step [3500/9247], Loss: 4.7237, Perplexity: 112.5825\n",
      "Epoch [2/2], Step [3600/9247], Loss: 4.5945, Perplexity: 98.9371\n",
      "Epoch [2/2], Step [3700/9247], Loss: 4.9962, Perplexity: 147.8576\n",
      "Epoch [2/2], Step [3800/9247], Loss: 4.8015, Perplexity: 121.6952\n",
      "Epoch [2/2], Step [3900/9247], Loss: 4.7627, Perplexity: 117.0640\n",
      "Epoch [2/2], Step [4000/9247], Loss: 4.6809, Perplexity: 107.8650\n",
      "Epoch [2/2], Step [4100/9247], Loss: 4.5803, Perplexity: 97.5432\n",
      "Epoch [2/2], Step [4200/9247], Loss: 4.5550, Perplexity: 95.1071\n",
      "Epoch [2/2], Step [4300/9247], Loss: 4.5394, Perplexity: 93.6363\n",
      "Epoch [2/2], Step [4400/9247], Loss: 4.9423, Perplexity: 140.0961\n",
      "Epoch [2/2], Step [4500/9247], Loss: 4.6768, Perplexity: 107.4227\n",
      "Epoch [2/2], Step [4600/9247], Loss: 5.2049, Perplexity: 182.1538\n",
      "Epoch [2/2], Step [4700/9247], Loss: 4.6650, Perplexity: 106.1617\n",
      "Epoch [2/2], Step [4800/9247], Loss: 4.6978, Perplexity: 109.7012\n",
      "Epoch [2/2], Step [4900/9247], Loss: 4.6473, Perplexity: 104.3050\n",
      "Epoch [2/2], Step [5000/9247], Loss: 4.6781, Perplexity: 107.5691\n",
      "Epoch [2/2], Step [5100/9247], Loss: 4.6507, Perplexity: 104.6618\n",
      "Epoch [2/2], Step [5200/9247], Loss: 4.5204, Perplexity: 91.8725\n",
      "Epoch [2/2], Step [5300/9247], Loss: 5.1274, Perplexity: 168.5810\n",
      "Epoch [2/2], Step [5400/9247], Loss: 4.7381, Perplexity: 114.2172\n",
      "Epoch [2/2], Step [5500/9247], Loss: 4.3844, Perplexity: 80.1866\n",
      "Epoch [2/2], Step [5600/9247], Loss: 4.4711, Perplexity: 87.4519\n",
      "Epoch [2/2], Step [5700/9247], Loss: 4.5384, Perplexity: 93.5381\n",
      "Epoch [2/2], Step [5800/9247], Loss: 4.6719, Perplexity: 106.8995\n",
      "Epoch [2/2], Step [5900/9247], Loss: 4.5874, Perplexity: 98.2423\n",
      "Epoch [2/2], Step [6000/9247], Loss: 4.6301, Perplexity: 102.5284\n",
      "Epoch [2/2], Step [6100/9247], Loss: 4.5844, Perplexity: 97.9455\n",
      "Epoch [2/2], Step [6200/9247], Loss: 4.4694, Perplexity: 87.3032\n",
      "Epoch [2/2], Step [6300/9247], Loss: 4.5021, Perplexity: 90.2057\n",
      "Epoch [2/2], Step [6400/9247], Loss: 4.4486, Perplexity: 85.5063\n",
      "Epoch [2/2], Step [6500/9247], Loss: 4.5971, Perplexity: 99.1972\n",
      "Epoch [2/2], Step [6600/9247], Loss: 4.5126, Perplexity: 91.1625\n",
      "Epoch [2/2], Step [6700/9247], Loss: 4.5226, Perplexity: 92.0781\n",
      "Epoch [2/2], Step [6800/9247], Loss: 4.3999, Perplexity: 81.4387\n",
      "Epoch [2/2], Step [6900/9247], Loss: 4.6019, Perplexity: 99.6781\n",
      "Epoch [2/2], Step [7000/9247], Loss: 4.8934, Perplexity: 133.4085\n",
      "Epoch [2/2], Step [7100/9247], Loss: 4.5681, Perplexity: 96.3569\n",
      "Epoch [2/2], Step [7200/9247], Loss: 5.5970, Perplexity: 269.6117\n",
      "Epoch [2/2], Step [7300/9247], Loss: 4.8049, Perplexity: 122.1050\n",
      "Epoch [2/2], Step [7400/9247], Loss: 4.9903, Perplexity: 146.9764\n",
      "Epoch [2/2], Step [7500/9247], Loss: 4.4451, Perplexity: 85.2054\n",
      "Epoch [2/2], Step [7600/9247], Loss: 4.6334, Perplexity: 102.8615\n",
      "Epoch [2/2], Step [7700/9247], Loss: 5.0614, Perplexity: 157.8066\n",
      "Epoch [2/2], Step [7800/9247], Loss: 4.7911, Perplexity: 120.4337\n",
      "Epoch [2/2], Step [7900/9247], Loss: 4.6810, Perplexity: 107.8807\n",
      "Epoch [2/2], Step [8000/9247], Loss: 4.9515, Perplexity: 141.3829\n",
      "Epoch [2/2], Step [8100/9247], Loss: 4.9919, Perplexity: 147.2103\n",
      "Epoch [2/2], Step [8200/9247], Loss: 4.9704, Perplexity: 144.0773\n",
      "Epoch [2/2], Step [8300/9247], Loss: 4.8962, Perplexity: 133.7867\n",
      "Epoch [2/2], Step [8400/9247], Loss: 4.8813, Perplexity: 131.8001\n",
      "Epoch [2/2], Step [8500/9247], Loss: 5.2714, Perplexity: 194.6858\n",
      "Epoch [2/2], Step [8600/9247], Loss: 4.6792, Perplexity: 107.6878\n",
      "Epoch [2/2], Step [8700/9247], Loss: 4.8057, Perplexity: 122.2085\n",
      "Epoch [2/2], Step [8800/9247], Loss: 4.7123, Perplexity: 111.3118\n",
      "Epoch [2/2], Step [8900/9247], Loss: 4.6260, Perplexity: 102.1041\n",
      "Epoch [2/2], Step [9000/9247], Loss: 4.6340, Perplexity: 102.9282\n",
      "Epoch [2/2], Step [9100/9247], Loss: 4.4608, Perplexity: 86.5565\n",
      "Epoch [2/2], Step [9200/9247], Loss: 4.7470, Perplexity: 115.2356\n",
      "Epoch [2/2], Step [9247/9247], Loss: 4.7129, Perplexity: 111.3742\n",
      "Saving the model\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        \n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "        \n",
    "        target_captions = captions[:, 1:].to(device)\n",
    "        training_captions = captions[:, :captions.shape[1]-1].to(device)\n",
    "        \n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "#         captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, training_captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), target_captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "\n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        print(\"\\nSaving the model\")\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
