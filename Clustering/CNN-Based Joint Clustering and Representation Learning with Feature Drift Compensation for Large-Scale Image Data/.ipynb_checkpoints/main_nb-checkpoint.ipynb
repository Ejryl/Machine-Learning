{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers, optimizers, datasets, models, utils, losses, callbacks\n",
    "import keras.backend as K\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_clusters(centroids, data) -> np.array:\n",
    "    \"\"\"\n",
    "        Assigns the labels to the images based on the distance from \n",
    "        the centroid\n",
    "        \n",
    "        Returns:\n",
    "            array of labels \n",
    "    \"\"\"\n",
    "    \n",
    "    # reminder to pass the right data\n",
    "    assert data.shape[1] == 10 \n",
    "    \n",
    "    return np.array([np.argmin(np.square([euclidean(u=centroid, v=feature) \n",
    "                                         for centroid in centroids])) \n",
    "                    for feature in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign clusters function\n",
    "def assign_clusters(population, labels):\n",
    "    \"\"\"\n",
    "        Assigns the images to clusters based on their labels\n",
    "        \n",
    "        Returns:\n",
    "            clusters (np.array):\n",
    "                images that were labeled 5, will be under index 4 in this array\n",
    "                \n",
    "            counts (np.array):\n",
    "                count of images in every cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    # init the vars\n",
    "    clusters = list()\n",
    "    counts = list()\n",
    "    \n",
    "    # iterate over classes\n",
    "    for i in range(10):\n",
    "        clusters.append(population[labels==i])\n",
    "        counts.append(len(population[labels==i]))\n",
    "    return np.array(clusters), np.array(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, axis=3) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - input image - - -\n",
    "# 28x28x1\n",
    "image_input = layers.Input(shape=(28,28,1))\n",
    "\n",
    "\n",
    "# - - - CNN - - - \n",
    "# first convolution\n",
    "# 14x14x32\n",
    "conv_1 = layers.Conv2D(filters=32, kernel_size=(2,2), strides=(2,2), \n",
    "                       activation=\"relu\", padding=\"valid\", name=\"conv_1\")(image_input)\n",
    "\n",
    "# second convolution\n",
    "# 7x7x64\n",
    "conv_2 = layers.Conv2D(filters=64, kernel_size=(2,2), strides=(2,2), \n",
    "                       activation=\"relu\", padding=\"valid\", name=\"conv_2\")(conv_1)\n",
    "# - - - CNN - - - \n",
    "\n",
    "\n",
    "# - - - Adaptation Layers - - -\n",
    "ada_3 = layers.Conv2D(filters=128, kernel_size=(2,2), strides=(2,2),\n",
    "                     activation=\"relu\", padding=\"same\", name=\"ada_1\")(conv_2)\n",
    "\n",
    "ada_4 = layers.Conv2D(filters=10, kernel_size=(2,2), strides=(2,2),\n",
    "                     activation=\"relu\", padding=\"same\", name=\"ada_2\")(ada_3)\n",
    "# - - - Adaptation Layers - - - \n",
    "\n",
    "\n",
    "# - - - Global Pool - - -\n",
    "global_max_pool = layers.GlobalMaxPool2D()(ada_4)\n",
    "# - - - Global Pool - - -\n",
    "\n",
    "\n",
    "# - - - FC9 - - -\n",
    "fc = layers.Dense(units=10, activation='relu', name='fc')(global_max_pool)\n",
    "# - - - FC9 - - -\n",
    "\n",
    "\n",
    "# - - - SOFTMAX - - -\n",
    "softmax = layers.Dense(units=10, activation='softmax', name='softmax')(fc)\n",
    "# - - - SOFTMAX - - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass of the K randomly selected images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where hell starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose K - (10) random images out of the set to use as initial cluster centroids\n",
    "index_list = np.arange(len(x_train))\n",
    "\n",
    "# get 10 random indices\n",
    "random_indices = np.random.choice(a=index_list, size=10, replace=False)\n",
    "\n",
    "# get the corresponding 10 images\n",
    "initial_random_images = x_train[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 6 2 2 2 6 6 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# define the K.function to get the centroids\n",
    "ccnn_function = K.function(inputs=[image_input], outputs=[softmax])\n",
    "\n",
    "# get the initial centroids\n",
    "initial_centroids = ccnn_function([initial_random_images])[0]\n",
    "\n",
    "# get the labels of the initial centroids\n",
    "# ARGMAX since softmax outputs the probabilities\n",
    "ccnn_initial_labels = np.argmax(initial_centroids, 1)\n",
    "\n",
    "# print the initial labels\n",
    "print(ccnn_initial_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59492, 42410, 56477, 32314,  6661, 55999, 46247, 48428, 43234,\n",
       "       31748])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current centroids\n",
    "random_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass of the rest of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the mask to drop the initial indices\n",
    "mask = np.ones(shape=index_list.shape)\n",
    "mask[random_indices] = False\n",
    "\n",
    "# get the other images tensor\n",
    "other_images = x_train[mask.astype(np.bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass the rest of the images\n",
    "other_images_features = ccnn_function([other_images])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions of the other images based on the CNN\n",
    "other_images_predictions = np.argmax(other_images_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pseudo-ground truth labels\n",
    "other_images_labels = get_labels_from_clusters(centroids=initial_centroids, data=other_images_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the *labels* and the *predictions* to define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the labels\n",
    "labels = utils.to_categorical(y=other_images_labels, num_classes=10)\n",
    "predictions = utils.to_categorical(y=other_images_predictions, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = models.Model(inputs=image_input, outputs=softmax)\n",
    "\n",
    "# define metrics\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "# define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "callbacks_ = [early_stopping]\n",
    "\n",
    "# define loss\n",
    "# predictions_ = K.constant(predictions)\n",
    "# labels_ = K.constant(labels)\n",
    "loss_ = losses.categorical_crossentropy\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=loss_, optimizer=optimizers.SGD(lr=0.001), metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47992 samples, validate on 11998 samples\n",
      "Epoch 1/10\n",
      "47992/47992 [==============================] - 17s 355us/step - loss: 2.1245 - acc: 0.2377 - val_loss: 2.0888 - val_acc: 0.2397\n",
      "Epoch 2/10\n",
      "47992/47992 [==============================] - 18s 371us/step - loss: 2.0700 - acc: 0.2377 - val_loss: 2.0439 - val_acc: 0.2397\n",
      "Epoch 3/10\n",
      "47992/47992 [==============================] - 17s 348us/step - loss: 2.0287 - acc: 0.2381 - val_loss: 2.0055 - val_acc: 0.2445\n",
      "Epoch 4/10\n",
      "47992/47992 [==============================] - 16s 339us/step - loss: 1.9868 - acc: 0.2989 - val_loss: 1.9592 - val_acc: 0.3316\n",
      "Epoch 5/10\n",
      "47992/47992 [==============================] - 16s 343us/step - loss: 1.9313 - acc: 0.3300 - val_loss: 1.8955 - val_acc: 0.3234\n",
      "Epoch 6/10\n",
      "47992/47992 [==============================] - 16s 343us/step - loss: 1.8567 - acc: 0.3379 - val_loss: 1.8113 - val_acc: 0.3512\n",
      "Epoch 7/10\n",
      "47992/47992 [==============================] - 16s 337us/step - loss: 1.7690 - acc: 0.3821 - val_loss: 1.7219 - val_acc: 0.3974\n",
      "Epoch 8/10\n",
      "47992/47992 [==============================] - 16s 333us/step - loss: 1.6816 - acc: 0.4232 - val_loss: 1.6381 - val_acc: 0.4332\n",
      "Epoch 9/10\n",
      "47992/47992 [==============================] - 16s 335us/step - loss: 1.6010 - acc: 0.4527 - val_loss: 1.5609 - val_acc: 0.4561\n",
      "Epoch 10/10\n",
      "47992/47992 [==============================] - 17s 346us/step - loss: 1.5262 - acc: 0.4748 - val_loss: 1.4915 - val_acc: 0.4817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2afa99eaac8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(x=other_images, y=labels, validation_split=0.20, epochs=10, verbose=1, callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we got the new features from the CNN\n",
    "new_features = ccnn_function([other_images])[0]\n",
    "\n",
    "# now we are going to assign them to the old centroids\n",
    "new_labels = get_labels_from_clusters(centroids=initial_centroids, data=new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the clusters and counts\n",
    "clusters, counts = assign_clusters(labels=new_labels, population=other_images)\n",
    "\n",
    "# replace zeros in the counts\n",
    "counts[counts == 0] = 2\n",
    "\n",
    "# get gammas\n",
    "gammas = 1 / counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 28, 28, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,10) (59990,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-5fbb9dcee6f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_centroids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgammas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_centroids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgammas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,10) (59990,10) "
     ]
    }
   ],
   "source": [
    "new_centroids = np.multiply((1 - gammas), initial_centroids) + np.multiply(gammas, new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.58397933e-03, 2.64725347e-05, 6.30914826e-05, 3.86847195e-04,\n",
       "       1.01832994e-03, 3.44827586e-02, 5.00000000e-01, 5.37634409e-04,\n",
       "       1.91570881e-03, 5.00000000e-01])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_labels(centroids=initial_centroids_features, data=new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_clusters(new_features, new_features_labels_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tqdm(range(10)):\n",
    "    \n",
    "    # get the new feature vector by forward pass of the CNN\n",
    "    new_features = ccnn_function([x_train])[0]\n",
    "    \n",
    "    # form new clusters\n",
    "    kmeans = KMeans(n_clusters=10).fit(new_features)\n",
    "    \n",
    "    # get the new labels\n",
    "    labels_kmeans_onehot = utils.to_categorical(y=kmeans.labels_, num_classes=10)\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(x=x_train, y=labels_kmeans_onehot, \n",
    "              validation_split=0.20, epochs=10, verbose=0, \n",
    "              callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(np.arange(len(x_train)), replace=False, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_images = x_train[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = y_train[random_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(ccnn_function([random_images])[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels == predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(random_images[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:re_model]",
   "language": "python",
   "name": "conda-env-re_model-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
